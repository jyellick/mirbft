/*
Copyright IBM Corp. All Rights Reserved.

SPDX-License-Identifier: Apache-2.0
*/

syntax = "proto3";

package mirbftpb;

// To re-generate, run:
//   protoc --go_out=. mirbft.proto
// or simply run go generate

// NetworkConfig contains the parameters which must be agreed upon by
// the entire network.  It must be serialized and reflected in the state
// snapshots and their corresponding checkpoint values.
message NetworkConfig {
        // Nodes represent the active nodeIDs in the network.
        // The number of nodeIDs corresponds to the size of the network.
        repeated uint64 nodes = 1;

        // CheckpointInterval is how often checkpoints are taken.  In terms of
        // of sequence numbers, this is multiplied by the configured number of
        // buckets, so that it scales naturally as the number of buckets increases
        // or decreases.
        int32 checkpoint_interval = 2;

        // MaxEpochLength is the maximum number of sequence numbers which may preprepare
        // in an epoch.  This is to force bucket rotation even when the system is otherwise
        // in a healthy state.  Setting this value to uint64_max will effectively disable
        // graceful epoch changes.
        uint64 max_epoch_length = 3;

        // NumberOfBuckets is the number of buckets the network is configured to operate over.
        // Each bucket is a partition of the request space.  Typically, number of buckets should
        // be nodes * m, where 'm' is some small constant.  Setting this value to 1 effectively
        // reduces Mir to PBFT.
        int32 number_of_buckets = 4;

        // F is the number of byzantine faults tolerated by the network.
        // It must be less than len(nodes)/3 (truncated).  The 'F' parameter
        // need not be maximal, ie, a network of 9 nodes with 'F' set to 1 may
        // simultaneously tolerate 1 byzantine fault, and 2 crash faults.  Whereas
        // when F=2, that 9 node network may only tolerate 2 crash faults.  Note
        // usually, a maximal value makes sense.  For instance in a network of 7
        // nodes F=1, and F=2 both provide crash tolerance of only 2 nodes.  The
        // following table summarizes the number of crash faults tolerated for
        // a given network of size N and number of byzantine faults tolerated F.
        //
        //    |           F           |
        //    | 0 | 1 | 2 | 3 | 4 | 5 |
        // N --------------------------
        // 1  | 0 |   |   |   |   |   |
        // 2  | 0 |   |   |   |   |   |
        // 3  | 1 |   |   |   |   |   |
        // 4  | 1 | 1 |   |   |   |   |
        // 5  | 2 | 1 |   |   |   |   |
        // 6  | 2 | 1 |   |   |   |   |
        // 7  | 3 | 2 | 2 |   |   |   |
        // 8  | 3 | 3 | 2 |   |   |   |
        // 9  | 4 | 3 | 2 |   |   |   |
        // 10 | 4 | 4 | 3 | 3 |   |   |
        // 11 | 5 | 4 | 4 | 3 |   |   |
        // 12 | 5 | 5 | 4 | 4 |   |   |
        // 13 | 6 | 5 | 5 | 4 | 4 |   |
        // 14 | 6 | 6 | 5 | 5 | 4 |   |
        // 15 | 7 | 6 | 6 | 5 | 5 |   |
        // 16 | 7 | 7 | 6 | 6 | 5 | 5 |
        // 17 | 8 | 7 | 7 | 6 | 6 | 5 |
        int32 f = 5;
}

// QEntry is an entry which must be persisted before a batch is Preprepared (ie,
// before a Preprepare or Prepare message is sent).
message QEntry {
        uint64 epoch = 1;
        uint64 seq_no = 2;
        bytes digest = 3;
        repeated Request requests = 4;
}

// PEntry is an entry which must be persisted before a batch is Prepared (ie,
// before a Commit message is sent).
message PEntry {
        uint64 epoch = 1;
        uint64 seq_no = 2;
        bytes digest = 3;
}

message Msg {
    oneof type {
        Preprepare preprepare = 1;
        Prepare prepare = 2;
        Commit commit = 3;
        Forward forward = 4;
        Checkpoint checkpoint = 5;
        Suspect suspect = 6;
        EpochChange epoch_change = 7;
        NewEpoch new_epoch = 8;
        NewEpochEcho new_epoch_echo = 9;
        NewEpochReady new_epoch_ready = 10;
    }
}

message RequestData {
    bytes client_id = 1;
    uint64 req_no = 2;
    bytes data = 3;
    bytes signature = 4;
}

message Request {
    bytes client_id = 1;
    uint64 req_no = 2;
    bytes digest = 3;
}

message Preprepare {
    uint64 seq_no = 1;
    uint64 epoch = 2;
    repeated Request batch = 3;
}

message Prepare {
    uint64 seq_no = 1;
    uint64 epoch = 2;
    bytes digest = 3;
}

message Commit {
    uint64 seq_no = 1;
    uint64 epoch = 2;
    bytes digest = 3;
}

message Checkpoint {
    uint64 seq_no = 1;
    bytes value = 2;
}

message Forward {
    RequestData request_data = 1;
}

message Suspect {
    uint64 epoch = 1;
}

// EpochChange messages are used to implement the classical PBFT view-change
// protocol, (very) slightly modified to adapt to Mir.  The assorted sets
// are encoded as repeated fields, rather than as maps for ease of serialization
// and particularly for computing a digest to attest to.  If any set contains
// a duplicated entry, the message may be discarded as byzantine.
message EpochChange {
    // attestation should be a signature covering the remainder of the fields
    // in the message.  additional information may optionally be encoded in the
    // attestation.
    bytes attestation = 1;

    uint64 new_epoch = 2;

    // c_set contains the entries for the C-set as defined by the classical
    // PBFT view-change protocol.
    repeated Checkpoint checkpoints = 3;

    message SetEntry {
        uint64 epoch = 1;
        uint64 seq_no = 2;
        bytes digest = 3;
    }

    // p_set contains the entries for the P-set as defined by the classical
    // PBFT view-change protocol.  
    repeated SetEntry p_set = 4;

    // q_set contains the entries for the Q-set as defined by the classical
    // PBFT view-change protocol.
    repeated SetEntry q_set = 5;
}

message EpochConfig {
    // number of this new epoch
    uint64 number = 1;

    Checkpoint starting_checkpoint = 2;

    repeated uint64 leaders = 3;

    // final_preprepares finalizes the last checkpoint window or windows
    // which some correct replica preprepared a sequence in. The entries are
    // digests indexed by sequence number offset by the starting_checkpoint
    // seq_no. An empty digest corresponds to a null request.
    repeated bytes final_preprepares = 4;
}

// NewEpoch is akin to the NewView message in classical PBFT and follows the same
// semantics.  Optionally, for graceful epoch change, the epoch_changes field may
// be empty.  In the event that the previous epoch does not complete gracefully,
// the graceful NewEpoch is ignored.  Unlike in classical PBFT, we employ a classical
// Bracha reliable broadcast on embedded config.  A replica should respond to a NewEpoch
// message with a NewEpochEcho (assuming that the NewEpoch message is validly constructed).
message NewEpoch {
    EpochConfig config = 1;

    message RemoteEpochChange {
        uint64 node_id = 1;
        EpochChange epoch_change = 2;
    }

    // epoch_changes must contains at least 2f+1 EpochChange messages from
    // replicas in the network.  If two EpochChanges originated from the same
    // replica, then the NewEpoch message is invalid.
    repeated RemoteEpochChange epoch_changes = 2;
}

// NewEpochReady is for the second round of the classical Bracha reliable broadcast.  Note,
// that the message embeds only the config.  This is because the config is derived from
// the epoch_changes, and a correct replica will only echo the request if the config is validly
// constructed.  Since the echo phase only proceeds to ready if 2f+1 echos occur, some (actually, f+1)
// correct replicas must have validated the new config according to the epoch_changes.
message NewEpochEcho {
    EpochConfig config = 1;
}

// NewEpochReady is for the final round fo the classical Bracha reliable broadcast.
message NewEpochReady {
    EpochConfig config = 1;
}
