/*
Copyright IBM Corp. All Rights Reserved.

SPDX-License-Identifier: Apache-2.0
*/

syntax = "proto3";

package mirbftpb;

option go_package = "github.com/IBM/mirbft/mirbftpb";

// To re-generate, run:
//   protoc --go_out=. mirbft.proto
// or simply run go generate

// NetworkState contains the configuration agreed to by all nodes in the network
// as well as the current client statuses.  NetworkState must be reflected in the
// state digest for checkpoints.  The easiest way to accomplish this is by serializing
// the structure and including it in the application state.  Note, when there are a large
// number of clients, performing a custom serialization may be desirable.
message NetworkState {
    message Config {
        // Nodes represent the active nodeIDs in the network.
        // The number of nodeIDs corresponds to the size of the network.
        repeated uint64 nodes = 1;

        // CheckpointInterval is how often checkpoints are taken.  In terms of
        // of sequence numbers, this is multiplied by the configured number of
        // buckets, so that it scales naturally as the number of buckets increases
        // or decreases.
        int32 checkpoint_interval = 2;

        // MaxEpochLength is the maximum number of sequence numbers which may preprepare
        // in an epoch.  This is to force bucket rotation even when the system is otherwise
        // in a healthy state.  Setting this value to uint64_max will effectively disable
        // graceful epoch changes.
        uint64 max_epoch_length = 3;

        // NumberOfBuckets is the number of buckets the network is configured to operate over.
        // Each bucket is a partition of the request space.  Typically, number of buckets should
        // be nodes * m, where 'm' is some small constant.  Setting this value to 1 effectively
        // reduces Mir to PBFT.
        int32 number_of_buckets = 4;

        // F is the number of byzantine faults tolerated by the network.
        // It must be less than len(nodes)/3 (truncated).  The 'F' parameter
        // need not be maximal, ie, a network of 9 nodes with 'F' set to 1 may
        // simultaneously tolerate 1 byzantine fault, and 2 crash faults.  Whereas
        // when F=2, that 9 node network may only tolerate 2 crash faults.  Note
        // usually, a maximal value makes sense.  For instance in a network of 7
        // nodes F=1, and F=2 both provide crash tolerance of only 2 nodes.  The
        // following table summarizes the number of crash faults tolerated for
        // a given network of size N and number of byzantine faults tolerated F.
        //
        //    |           F           |
        //    | 0 | 1 | 2 | 3 | 4 | 5 |
        // N --------------------------
        // 1  | 0 |   |   |   |   |   |
        // 2  | 0 |   |   |   |   |   |
        // 3  | 1 |   |   |   |   |   |
        // 4  | 1 | 1 |   |   |   |   |
        // 5  | 2 | 1 |   |   |   |   |
        // 6  | 2 | 1 |   |   |   |   |
        // 7  | 3 | 2 | 2 |   |   |   |
        // 8  | 3 | 3 | 2 |   |   |   |
        // 9  | 4 | 3 | 2 |   |   |   |
        // 10 | 4 | 4 | 3 | 3 |   |   |
        // 11 | 5 | 4 | 4 | 3 |   |   |
        // 12 | 5 | 5 | 4 | 4 |   |   |
        // 13 | 6 | 5 | 5 | 4 | 4 |   |
        // 14 | 6 | 6 | 5 | 5 | 4 |   |
        // 15 | 7 | 6 | 6 | 5 | 5 |   |
        // 16 | 7 | 7 | 6 | 6 | 5 | 5 |
        // 17 | 8 | 7 | 7 | 6 | 6 | 5 |
        int32 f = 5;
    }

    message Client {
        uint64 id = 1;
	uint32 width = 2;
	uint64 low_watermark = 3;
	// CommittedMask is a bitmask of up to length 'width', indicating which request numbers
	// beyond the low_watermark have committed.  If non-empty, the last byte is never 0,
	// and all request numbers beyond the last bit are uncommitted.  Note, a repeated bool
	// would be much more natural, but very space inefficient per proto's implementation.
	bytes committed_mask = 4;
    }

    Config config = 1;

    repeated Client clients = 2;

    repeated Reconfiguration pending_reconfigurations = 3;
}

message Reconfiguration {
    oneof type {
        uint64 new_client = 1;
        uint64 remove_client = 2;
        NetworkState.Config new_config = 3;
    }
}

// Persistent contains data that should be persited by lib user
message Persistent {
    oneof type {
        QEntry q_entry = 1;
        PEntry p_entry = 2;
        CEntry c_entry = 3;
	EpochChange epoch_change = 4;
	NewEpochConfig new_epoch_echo = 5;
	NewEpochConfig new_epoch_ready = 6;
	EpochConfig new_epoch_start = 7; // XXX Probably overkill? See refactoring with a uint64
	Suspect suspect = 8;
	// TODO, suspect_ready
    }
}

// QEntry is an entry which must be persisted before a batch is Preprepared (ie,
// before a Preprepare or Prepare message is sent).  Note, any RequestAck referenced
// by the QEntry is already persisted to disk.
message QEntry {
    uint64 seq_no = 2;
    bytes digest = 3;
    repeated RequestAck requests = 4;
}

// PEntry is an entry which must be persisted before a batch is Prepared (ie,
// before a Commit message is sent).
message PEntry {
    uint64 seq_no = 2;
    bytes digest = 3;
}

// CEntry is an entry which must be persisted before a Checkpoint message is sent.
message CEntry {
    uint64 seq_no = 1;
    bytes checkpoint_value = 2;
    NetworkState network_state = 3;
    uint64 current_epoch = 4;
}

message Msg {
    oneof type {
        Preprepare preprepare = 1;
        Prepare prepare = 2;
        Commit commit = 3;
        Checkpoint checkpoint = 4;
        Suspect suspect = 5;
        EpochChange epoch_change = 6;
        EpochChangeAck epoch_change_ack = 7;
        NewEpoch new_epoch = 8;
        NewEpochEcho new_epoch_echo = 9;
        NewEpochReady new_epoch_ready = 10;
	FetchBatch fetch_batch = 11;
	ForwardBatch forward_batch = 12;
	RequestAck fetch_request = 13;
        ForwardRequest forward_request = 14;
	RequestAck request_ack = 15;
    }
}

message FetchBatch {
    uint64 seq_no = 1;
    bytes digest = 2;
}

message ForwardBatch {
    uint64 seq_no = 1;
    repeated RequestAck request_acks = 2;
    bytes digest = 3;
}

message ForwardRequest {
    RequestAck request_ack = 1;
    bytes request_data = 2;
}

message Request {
    uint64 client_id = 1;
    uint64 req_no = 2;
    bytes data = 3;
}

message RequestAck {
    uint64 client_id = 1;
    uint64 req_no = 2;
    bytes digest = 3;
}

message Preprepare {
    uint64 seq_no = 1;
    uint64 epoch = 2;
    repeated RequestAck batch = 3;
}

message Prepare {
    uint64 seq_no = 1;
    uint64 epoch = 2;
    bytes digest = 3;
}

message Commit {
    uint64 seq_no = 1;
    uint64 epoch = 2;
    bytes digest = 3;
}

message Checkpoint {
    uint64 seq_no = 1;
    bytes value = 2;
}

message Suspect {
    uint64 epoch = 1;
}

// EpochChange messages are used to implement the classical PBFT view-change
// protocol, (very) slightly modified to adapt to Mir.  The assorted sets
// are encoded as repeated fields, rather than as maps for ease of serialization
// and particularly for computing a digest to attest to.  If any set contains
// a duplicated entry, the message may be discarded as byzantine.
message EpochChange {
    uint64 new_epoch = 1;

    // c_set contains the entries for the C-set as defined by the classical
    // PBFT view-change protocol.
    repeated Checkpoint checkpoints = 2;

    message SetEntry {
        uint64 epoch = 1;
        uint64 seq_no = 2;
        bytes digest = 3;
    }

    // p_set contains the entries for the P-set as defined by the classical
    // PBFT view-change protocol.  
    repeated SetEntry p_set = 3;

    // q_set contains the entries for the Q-set as defined by the classical
    // PBFT view-change protocol.
    repeated SetEntry q_set = 4;
}

// EpochChangeAck messages are broadcast in response to receiving a valid epoch change
// from a replica.  Replicas collect these epoch change ack messages, and when there are 2f+1
// such messages begin to count that epoch change as appropriately broadcast for purposes of
// the epoch change timer.
message EpochChangeAck {
    uint64 originator = 1;

    // epoch_change is included fully instead of echo-ing the digest as suggested by the original
    // PBFT paper.  This is purely to prevent requiring a separate fetch step for missing epoch change
    // requests.  Although this is slightly heavier, because ungraceful epoch change is not a performance
    // optimal path, the simplification seems worthwhile.
    EpochChange epoch_change = 2;
}

message EpochConfig {
    // number of this new epoch
    uint64 number = 1;

    repeated uint64 leaders = 2;

    uint64 planned_expiration = 3;
}

message NewEpochConfig {
    EpochConfig config = 1;

    Checkpoint starting_checkpoint = 2;

    // final_preprepares finalizes the last checkpoint window or windows
    // which some correct replica preprepared a sequence in. The entries are
    // digests indexed by sequence number offset by the starting_checkpoint
    // seq_no. An empty digest corresponds to a null request.
    repeated bytes final_preprepares = 3;
}

// NewEpoch is akin to the NewView message in classical PBFT and follows the same
// semantics.  Optionally, for graceful epoch change, the epoch_changes field may
// be empty.  In the event that the previous epoch does not complete gracefully,
// the graceful NewEpoch is ignored.  Unlike in classical PBFT, we employ a classical
// Bracha reliable broadcast on embedded config.  A replica should respond to a NewEpoch
// message with a NewEpochEcho (assuming that the NewEpoch message is validly constructed).
message NewEpoch {
    NewEpochConfig new_config = 1;

    message RemoteEpochChange {
        uint64 node_id = 1;
        bytes digest = 2;
    }

    // epoch_changes must contains at least 2f+1 EpochChange messages references from
    // replicas in the network.  If two EpochChanges references originated from the same
    // replica, then the NewEpoch message is invalid.
    repeated RemoteEpochChange epoch_changes = 2;
}

// NewEpochReady is for the second round of the classical Bracha reliable broadcast.  Note,
// that the message embeds only the config.  This is because the config is derived from
// the epoch_changes, and a correct replica will only echo the request if the config is validly
// constructed.  Since the echo phase only proceeds to ready if 2f+1 echos occur, some (actually, f+1)
// correct replicas must have validated the new config according to the epoch_changes.
message NewEpochEcho {
    NewEpochConfig new_config = 1;
}

// NewEpochReady is for the final round fo the classical Bracha reliable broadcast.
message NewEpochReady {
    NewEpochConfig new_config = 1;
}

// StateEvent represents an event occurring inside of the state machine
// and is used for tracing and debugging purposes only.
message StateEvent {
    message InitialParameters {
        uint64 id = 1;
        uint32 batch_size = 2;
        uint32 heartbeat_ticks = 3;
        uint32 suspect_ticks = 4;
        uint32 new_epoch_timeout_ticks = 5;
        uint32 buffer_size = 6;
    }

    message PersistedEntry {
        uint64 index = 1;
        Persistent data = 2;
    }

    message LoadCompleted {}

    message ActionResults {
        repeated HashResult digests = 1;
        repeated CheckpointResult checkpoints = 2;
    }

    message Proposal {
        Request request = 1;
    }

    message InboundMsg {
        uint64 source = 1;
        Msg msg = 2;
    }

    message TickElapsed {}

    message Ready{}

    oneof type {
        InitialParameters initialize = 1;
	PersistedEntry load_entry = 2;
	LoadCompleted complete_initialization = 3;
        ActionResults add_results = 4;
        Proposal propose = 5;
        InboundMsg step = 6;
	TickElapsed tick = 7;
	Ready actions_received = 8;
    }
}

message HashResult {
    message Request {
        uint64 source = 1;
        mirbftpb.Request request = 2;
    }

    message VerifyRequest { 
        uint64 source = 1;
        mirbftpb.RequestAck request_ack = 2;
        bytes request_data = 3;
    }

    message Batch {
        uint64 source = 1;
        uint64 epoch = 2;
        uint64 seq_no = 3;
        repeated mirbftpb.RequestAck request_acks = 5;
    }

    message VerifyBatch { 
        uint64 source = 1;
        uint64 seq_no = 2;
        repeated mirbftpb.RequestAck request_acks = 3;
        bytes expected_digest = 4;
    }

    message EpochChange {
        uint64 source = 1;
        uint64 origin = 2;
        mirbftpb.EpochChange epoch_change = 3;
    }

    bytes digest = 1;
    oneof type {
        Request request = 2;
        Batch batch = 3;
        EpochChange epoch_change = 4;
        VerifyBatch verify_batch = 5;
        VerifyRequest verify_request = 6;
    }
}

message CheckpointResult {
        uint64 seq_no = 1;
        NetworkState network_state = 2;
        bytes value = 4;
}
